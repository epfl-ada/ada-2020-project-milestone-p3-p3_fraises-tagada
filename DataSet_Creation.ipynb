{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import statsmodels.formula.api as smf\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Data_Logit(PATH, cols_to_use):\n",
    "    \n",
    "    # Keep the data we need\n",
    "    \n",
    "    # Load the csv with only the desired columns\n",
    "    df = pd.read_csv(PATH, usecols = cols_to_use)\n",
    "    # Drop the Nan values\n",
    "    df.dropna(inplace = True)\n",
    "    # Only keep hispanic, black and white people\n",
    "    df = df.iloc[[x in ['hispanic', 'black', 'white'] for x in df.subject_race]]\n",
    "    # Convert date to ordinal\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.date = df.date.map(dt.datetime.toordinal)\n",
    "    # Only keep data after 2009\n",
    "    df = df[df.date > dt.datetime.toordinal(dt.datetime(2009,1,1))]\n",
    "    \n",
    "    # Create the search_rates\n",
    "    \n",
    "    # Make search_conducted be 0 or 1\n",
    "    df.search_conducted =  df.search_conducted.astype(int)\n",
    "    # Train a model\n",
    "    res = smf.logit(formula = 'search_conducted ~ date + C(subject_race):C(subject_sex)', data = df).fit()\n",
    "    # Get the search_rates\n",
    "    p = res.predict(df[['date', 'subject_race', 'subject_sex']])\n",
    "    df['search_rate'] = p\n",
    "    # No need for search_conducted anymore\n",
    "    df.drop('search_conducted', axis = 1, inplace = True)\n",
    "    # Make the date be datetime again\n",
    "    df.date = df.date.map(dt.date.fromordinal)\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Not_Zip/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "States = ['AZ', 'CA', 'CT', 'IL', 'NC', 'OH', 'RI', 'SC', 'TX', 'WI']\n",
    "cols_to_use = ['date', 'subject_race', 'subject_sex', 'search_conducted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.218610\n",
      "         Iterations 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.154180\n",
      "         Iterations 9\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.160390\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.184287\n",
      "         Iterations 8\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.114237\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.140794\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.148930\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.125029\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.089807\n",
      "         Iterations 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.077473\n",
      "         Iterations 16\n"
     ]
    }
   ],
   "source": [
    "for state in States:\n",
    "    \n",
    "    df = Create_Data_Logit(PATH+state+'.csv', cols_to_use)\n",
    "    df.to_csv('Logit_Files/'+state+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupyweek(df):\n",
    "    df = df.groupby(['subject_race', pd.Grouper(key = 'date', freq = '1W')]).mean()\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
